#!/usr/bin/env python
"""
í†µí•© ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸: SEC í¬ë¡¤ë§ + 4ëª… ì „ë¬¸ê°€ í† ë¡  íŒŒì´í”„ë¼ì¸

ì‚¬ìš©ë²•:
    python run.py --ticker GOOG                    # í¬ë¡¤ë§ + ë¶„ì„
    python run.py --ticker GOOG --skip-crawl       # í¬ë¡¤ë§ ìƒëµ, ë¶„ì„ë§Œ
    python run.py --ticker GOOG --crawl-only       # í¬ë¡¤ë§ë§Œ
    python run.py --ticker GOOG --save             # ê²°ê³¼ JSON ì €ì¥
"""

import argparse
import json
import os
from pathlib import Path
from datetime import datetime
from typing import Optional

from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()


def parse_args():
    parser = argparse.ArgumentParser(
        description="SEC í¬ë¡¤ë§ + 4ëª… ì „ë¬¸ê°€ í† ë¡  íŒŒì´í”„ë¼ì¸"
    )
    parser.add_argument("--ticker", required=True, help="ë¶„ì„í•  í‹°ì»¤ (ì˜ˆ: GOOG, AAPL)")
    parser.add_argument(
        "--skip-crawl",
        action="store_true",
        help="SEC í¬ë¡¤ë§ ìƒëµ (ì´ë¯¸ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°)",
    )
    parser.add_argument(
        "--crawl-only",
        action="store_true",
        help="SEC í¬ë¡¤ë§ë§Œ ì‹¤í–‰ (ë¶„ì„ ìƒëµ)",
    )
    parser.add_argument(
        "--save",
        action="store_true",
        help="ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥",
    )
    parser.add_argument(
        "--output-dir",
        type=str,
        default="data/agent_results",
        help="ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: data/agent_results)",
    )
    return parser.parse_args()


def run_crawling(ticker: str) -> dict:
    """SEC í¬ë¡¤ë§ ì‹¤í–‰"""
    from src.sec_crawler import SECCrawler
    from src.db import SECDatabase
    
    print("\n" + "=" * 100)
    print("ğŸ“¥ SEC í¬ë¡¤ë§ ì‹œì‘")
    print("=" * 100)
    
    sec_crawler = SECCrawler()
    db = SECDatabase()
    
    print(f"\n[{ticker}] SEC ê³µì‹œ í¬ë¡¤ë§ ì¤‘...")
    results = sec_crawler.crawl_filings_in_window(
        ticker,
        save_to_db=True,
        db=db,
        only_today=True,
        include_annual_quarterly=True,  # 10-K, 10-Q í•­ìƒ í¬í•¨
    )
    
    stats = {"total": 0, "10-K": False, "10-Q": False}
    if results:
        for metadata, file_path in results:
            form = metadata.get('form')
            print(f"  âœ… {form}: {file_path}")
            stats["total"] += 1
            if form == "10-K":
                stats["10-K"] = True
            if form == "10-Q":
                stats["10-Q"] = True
    else:
        print(f"  âšª ìƒˆë¡œìš´ ê³µì‹œ ì—†ìŒ (ê¸°ì¡´ ë°ì´í„° ì‚¬ìš©)")
    
    print(f"\nğŸ“Š í¬ë¡¤ë§ ê²°ê³¼: {stats['total']}ê±´ (10-K: {'âœ…' if stats['10-K'] else 'âŒ'}, 10-Q: {'âœ…' if stats['10-Q'] else 'âŒ'})")
    print("=" * 100)
    
    return stats


def run_analysis(ticker: str, save: bool = False, output_dir: str = "data/agent_results") -> dict:
    """4ëª… ì „ë¬¸ê°€ í† ë¡  íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    from multiagent.graph import run_multiagent_pipeline
    
    # LangSmith ì¶”ì  ìƒíƒœ í™•ì¸
    langsmith_enabled = os.getenv("LANGCHAIN_TRACING_V2") == "true"
    langsmith_project = os.getenv("LANGCHAIN_PROJECT", "stock-morning")
    
    print("\n" + "=" * 100)
    print(f"ğŸ¯ 4-EXPERT DEBATE PIPELINE START")
    print(f"ğŸ“Š Ticker: {ticker}")
    print(f"â° Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    if langsmith_enabled:
        print(f"ğŸ” LangSmith Tracing: âœ… Enabled (Project: {langsmith_project})")
        print(f"   ğŸ“ https://smith.langchain.com/o/{os.getenv('LANGSMITH_ORG', 'default')}/projects/p/{langsmith_project}")
    else:
        print(f"ğŸ” LangSmith Tracing: âš ï¸  Disabled")
    print("=" * 100)
    
    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    result = run_multiagent_pipeline(ticker)
    
    # JSON ì €ì¥
    if save:
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{ticker}_{timestamp}_debate.json"
        filepath = output_path / filename
        
        structured_conclusion = result.get("structured_conclusion")
        
        save_data = {
            "ticker": ticker,
            "timestamp": timestamp,
            "rounds": result.get("rounds", []),
            "conclusion": result.get("conclusion", ""),
            "readable_summary": result.get("readable_summary", ""),
            "debate_transcript": result.get("debate_transcript", ""),
        }
        
        if structured_conclusion:
            save_data["structured_conclusion"] = structured_conclusion.model_dump()
        
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(save_data, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {filepath}")
    
    return result


def main():
    args = parse_args()
    ticker = args.ticker.upper()
    
    print("\n" + "=" * 100)
    print(f"ğŸš€ STOCK MORNING - í†µí•© ë¶„ì„ íŒŒì´í”„ë¼ì¸")
    print(f"ğŸ“Š Ticker: {ticker}")
    print(f"â° ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 100)
    
    # 1ë‹¨ê³„: SEC í¬ë¡¤ë§
    if not args.skip_crawl:
        crawl_stats = run_crawling(ticker)
    else:
        print("\nâ­ï¸  SEC í¬ë¡¤ë§ ìƒëµ (--skip-crawl)")
    
    # 2ë‹¨ê³„: ì „ë¬¸ê°€ í† ë¡  ë¶„ì„
    if not args.crawl_only:
        result = run_analysis(ticker, save=args.save, output_dir=args.output_dir)
        
        # 3ë‹¨ê³„: ì„ì‹œ ë‰´ìŠ¤ íŒŒì¼ ì •ë¦¬
        cleanup_temp_files(ticker)
    else:
        print("\nâ­ï¸  ë¶„ì„ ìƒëµ (--crawl-only)")
        result = None
    
    # ì™„ë£Œ
    print("\n" + "=" * 100)
    print("âœ¨ PIPELINE COMPLETED")
    print(f"â° ì¢…ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 100)
    
    return result


def cleanup_temp_files(ticker: str):
    """ë¶„ì„ ì™„ë£Œ í›„ ì„ì‹œ ë‰´ìŠ¤ íŒŒì¼ ì •ë¦¬"""
    import shutil
    
    aws_results_dir = Path("aws_results")
    if aws_results_dir.exists():
        # í•´ë‹¹ í‹°ì»¤ì˜ ë‰´ìŠ¤ íŒŒì¼ë§Œ ì‚­ì œ
        ticker_files = list(aws_results_dir.glob(f"{ticker}_*.json"))
        if ticker_files:
            for f in ticker_files:
                f.unlink()
            print(f"\nğŸ§¹ ì„ì‹œ íŒŒì¼ ì •ë¦¬: {len(ticker_files)}ê°œ ë‰´ìŠ¤ íŒŒì¼ ì‚­ì œ")


if __name__ == "__main__":
    main()
