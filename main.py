"""
ë©”ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
SEC/ë‰´ìŠ¤ í¬ë¡¤ëŸ¬ì™€ Agent ì‹œìŠ¤í…œì„ ê´€ë¦¬í•©ë‹ˆë‹¤.
"""

from typing import Iterable, List, Optional

from src.sec_crawler import SECCrawler
from src.news_crawler import NewsCrawler
from src.database.data_fetcher import DataFetcher
from src.agents.base_agent import AgentManager
from src.config.settings import get_settings
from src.db import SECDatabase


def _resolved_tickers(tickers: Optional[Iterable[str]]) -> List[str]:
    if tickers:
        return [t.upper() for t in tickers]
    settings = get_settings()
    return [t.upper() for t in settings.tickers]


def run_sec_crawler(tickers: Optional[Iterable[str]] = None, only_today: bool = True):
    """
    SEC + ë‰´ìŠ¤ í¬ë¡¤ëŸ¬ ì‹¤í–‰ (ë¡œì»¬ DB ì €ì¥)
    """
    resolved = _resolved_tickers(tickers)
    if not resolved:
        print("âš ï¸  í¬ë¡¤ë§í•  í‹°ì»¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    print("\n" + "=" * 60)
    print("SEC/ë‰´ìŠ¤ í¬ë¡¤ëŸ¬ ì‹¤í–‰")
    print("=" * 60)

    sec_crawler = SECCrawler()
    news_crawler = NewsCrawler()
    db = SECDatabase()

    for ticker in resolved:
        print(f"\n[{ticker}] SEC í¬ë¡¤ë§ ì‹œì‘...")
        result = sec_crawler.crawl_latest_filing(
            ticker,
            save_to_db=True,
            db=db,
            only_today=only_today,
        )
        if result:
            metadata, file_path = result
            print(f"âœ… [{ticker}] SEC ì„±ê³µ: {metadata.get('form')} - {file_path}")
        else:
            print(f"âšª [{ticker}] ìƒˆë¡œìš´ ê³µì‹œ ì—†ìŒ")

        print(f"[{ticker}] ë‰´ìŠ¤ í¬ë¡¤ë§ ì‹œì‘...")
        articles = news_crawler.fetch_news(ticker)
        inserted = db.save_news_items(ticker, articles) if articles else 0
        print(f"ğŸ“° [{ticker}] ë‰´ìŠ¤ {inserted}/{len(articles) if articles else 0}ê±´ ì €ì¥")

    print("\n" + "=" * 60)
    print("SEC/ë‰´ìŠ¤ í¬ë¡¤ëŸ¬ ì‹¤í–‰ ì™„ë£Œ")
    print("=" * 60)


def run_agents(tickers: Optional[Iterable[str]] = None):
    """Agent ì‹œìŠ¤í…œ ì‹¤í–‰ (6ì‹œ~6ì‹œ ë°ì´í„° ì¡°íšŒ ë° ì²˜ë¦¬)"""
    resolved = _resolved_tickers(tickers)
    if not resolved:
        print("âš ï¸  Agentë¥¼ ì‹¤í–‰í•  í‹°ì»¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    print("\n" + "=" * 60)
    print("Agent ì‹œìŠ¤í…œ ì‹¤í–‰")
    print("=" * 60)

    fetcher = DataFetcher()
    print("\në°ì´í„° ì¡°íšŒ ì‹œì‘...")
    data_dict = fetcher.fetch_all_tickers(resolved, include_file_content=True)

    print("\nAgent ì²˜ë¦¬ ì‹œì‘...")
    agent_manager = AgentManager(resolved)
    results = agent_manager.process_all(data_dict)

    print("\nê²°ê³¼ ì €ì¥ ì¤‘...")
    for ticker, result in results.items():
        if result.get('status') == 'processed':
            agent = agent_manager.agents[ticker]
            agent.save_result(result)

    print("\n" + "=" * 60)
    print("Agent ì‹œìŠ¤í…œ ì‹¤í–‰ ì™„ë£Œ")
    print("=" * 60)


def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜: SEC/ë‰´ìŠ¤ ìˆ˜ì§‘ í›„ Agent ì‹¤í–‰
    """
    run_sec_crawler()
    run_agents()


if __name__ == "__main__":
    main()
